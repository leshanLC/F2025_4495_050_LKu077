{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74cc7123-ccc6-4401-964b-9f456926ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\lesha\\anaconda3\\lib\\site-packages (4.35.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\lesha\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\lesha\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from selenium) (2025.8.3)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\lesha\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d63ebf42-5151-4807-87fc-1a3716142201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Indeed Canada Job Scraper...\n",
      "Navigating to: https://ca.indeed.com/jobs?q=&l=Canada\n",
      "Found 15 job cards on this page\n",
      "Page 1/2 completed. Found 15 jobs so far.\n",
      "Navigating to: https://ca.indeed.com/jobs?q=&l=Canada&start=10\n",
      "Job cards not found, trying to continue...\n",
      "Found 0 job cards on this page\n",
      "Page 2/2 completed. Found 15 jobs so far.\n",
      "Successfully saved 15 jobs to canada_developer_jobs.csv\n",
      "\n",
      "First 5 job listings:\n",
      "\n",
      "1. Online ESL Tutors for Young Kids\n",
      "   Company: N/A\n",
      "   Location: N/A\n",
      "   Salary: Not specified\n",
      "\n",
      "2. Destination Specialist\n",
      "   Company: N/A\n",
      "   Location: N/A\n",
      "   Salary: Not specified\n",
      "\n",
      "3. Concierge (Entretien mÃ©nager)\n",
      "   Company: N/A\n",
      "   Location: N/A\n",
      "   Salary: Not specified\n",
      "\n",
      "4. Armed Guard\n",
      "   Company: N/A\n",
      "   Location: N/A\n",
      "   Salary: Not specified\n",
      "\n",
      "5. Journalier\n",
      "   Company: N/A\n",
      "   Location: N/A\n",
      "   Salary: Not specified\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "class IndeedSeleniumScraper:\n",
    "    def __init__(self, headless=True):\n",
    "        self.options = Options()\n",
    "        if headless:\n",
    "            self.options.add_argument('--headless')\n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        self.options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        self.options.add_experimental_option('useAutomationExtension', False)\n",
    "        self.options.add_argument('--disable-extensions')\n",
    "        self.options.add_argument('--disable-gpu')\n",
    "        self.options.add_argument('--window-size=1920,1080')\n",
    "        \n",
    "        # Real user agent\n",
    "        self.options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "        \n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=self.options\n",
    "        )\n",
    "        \n",
    "        # Hide automation detection\n",
    "        self.driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        self.jobs_data = []\n",
    "    \n",
    "    def scrape_jobs(self, job_title=\"software developer\", location=\"Toronto, ON\", max_pages=3):\n",
    "        \"\"\"Scrape jobs using Selenium\"\"\"\n",
    "        \n",
    "        try:\n",
    "            for page in range(max_pages):\n",
    "                start_param = page * 10\n",
    "                if page == 0:\n",
    "                    url = f\"https://ca.indeed.com/jobs?q={job_title.replace(' ', '+')}&l={location.replace(' ', '+').replace(',', '%2C')}\"\n",
    "                else:\n",
    "                    url = f\"https://ca.indeed.com/jobs?q={job_title.replace(' ', '+')}&l={location.replace(' ', '+').replace(',', '%2C')}&start={start_param}\"\n",
    "                \n",
    "                print(f\"Navigating to: {url}\")\n",
    "                self.driver.get(url)\n",
    "                \n",
    "                # Wait for page to load\n",
    "                time.sleep(random.uniform(3, 5))\n",
    "                \n",
    "                # Check for CAPTCHA\n",
    "                if self._check_captcha():\n",
    "                    print(\"CAPTCHA detected! Please solve it manually or try again later.\")\n",
    "                    break\n",
    "                \n",
    "                # Wait for job cards to load\n",
    "                try:\n",
    "                    WebDriverWait(self.driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.CSS_SELECTOR, '.job_seen_beacon, .cardOutline, .jobsearch-SerpJobCard'))\n",
    "                    )\n",
    "                except:\n",
    "                    print(\"Job cards not found, trying to continue...\")\n",
    "                \n",
    "                # Extract jobs from current page\n",
    "                self._extract_page_jobs()\n",
    "                \n",
    "                print(f\"Page {page + 1}/{max_pages} completed. Found {len(self.jobs_data)} jobs so far.\")\n",
    "                \n",
    "                # Random delay between pages\n",
    "                time.sleep(random.uniform(2, 4))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during scraping: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            self.driver.quit()\n",
    "        \n",
    "        return self.jobs_data\n",
    "    \n",
    "    def _check_captcha(self):\n",
    "        \"\"\"Check if CAPTCHA is present\"\"\"\n",
    "        try:\n",
    "            captcha_elements = self.driver.find_elements(By.ID, 'captcha')\n",
    "            captcha_input = self.driver.find_elements(By.ID, 'captcha-input')\n",
    "            return len(captcha_elements) > 0 or len(captcha_input) > 0\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def _extract_page_jobs(self):\n",
    "        \"\"\"Extract jobs from the current page\"\"\"\n",
    "        try:\n",
    "            # Try multiple selectors for job cards\n",
    "            selectors = [\n",
    "                'div.job_seen_beacon',\n",
    "                'div.cardOutline',\n",
    "                'div.jobsearch-SerpJobCard',\n",
    "                'div[data-jk]'\n",
    "            ]\n",
    "            \n",
    "            job_cards = []\n",
    "            for selector in selectors:\n",
    "                try:\n",
    "                    job_cards = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if job_cards:\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"Found {len(job_cards)} job cards on this page\")\n",
    "            \n",
    "            for card in job_cards:\n",
    "                job_info = self._extract_job_info(card)\n",
    "                if job_info:\n",
    "                    self.jobs_data.append(job_info)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting jobs from page: {e}\")\n",
    "    \n",
    "    def _extract_job_info(self, card):\n",
    "        \"\"\"Extract information from a single job card\"\"\"\n",
    "        try:\n",
    "            # Title\n",
    "            try:\n",
    "                title_elem = card.find_element(By.CSS_SELECTOR, 'h2.jobTitle, h2.title, a.jcs-JobTitle')\n",
    "                title = title_elem.text.strip()\n",
    "            except:\n",
    "                title = \"N/A\"\n",
    "            \n",
    "            # Company\n",
    "            try:\n",
    "                company_elem = card.find_element(By.CSS_SELECTOR, 'span.companyName, span.company')\n",
    "                company = company_elem.text.strip()\n",
    "            except:\n",
    "                company = \"N/A\"\n",
    "            \n",
    "            # Location\n",
    "            try:\n",
    "                location_elem = card.find_element(By.CSS_SELECTOR, 'div.companyLocation, div.location')\n",
    "                location = location_elem.text.strip()\n",
    "            except:\n",
    "                location = \"N/A\"\n",
    "            \n",
    "            # Salary\n",
    "            try:\n",
    "                salary_elem = card.find_element(By.CSS_SELECTOR, 'div.salary-snippet, span.salaryText')\n",
    "                salary = salary_elem.text.strip()\n",
    "            except:\n",
    "                salary = \"Not specified\"\n",
    "            \n",
    "            # Link\n",
    "            try:\n",
    "                link_elem = card.find_element(By.CSS_SELECTOR, 'a.jcs-JobTitle, a.jobtitle')\n",
    "                link = link_elem.get_attribute('href')\n",
    "                if link and link.startswith('/'):\n",
    "                    link = 'https://ca.indeed.com' + link\n",
    "            except:\n",
    "                link = \"N/A\"\n",
    "            \n",
    "            # Date\n",
    "            try:\n",
    "                date_elem = card.find_element(By.CSS_SELECTOR, 'span.date, span.datePosted')\n",
    "                date_posted = date_elem.text.strip()\n",
    "            except:\n",
    "                date_posted = \"N/A\"\n",
    "            \n",
    "            job_info = {\n",
    "                'title': title,\n",
    "                'company': company,\n",
    "                'location': location,\n",
    "                'salary': salary,\n",
    "                'link': link,\n",
    "                'date_posted': date_posted,\n",
    "                'scraped_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "            \n",
    "            return job_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting job info: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_to_csv(self, filename=\"indeed_jobs_selenium.csv\"):\n",
    "        \"\"\"Save results to CSV\"\"\"\n",
    "        if not self.jobs_data:\n",
    "            print(\"No jobs data to save.\")\n",
    "            return False\n",
    "        \n",
    "        df = pd.DataFrame(self.jobs_data)\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        print(f\"Successfully saved {len(self.jobs_data)} jobs to {filename}\")\n",
    "        return True\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Indeed Canada Job Scraper...\")\n",
    "    \n",
    "    # Initialize scraper (set headless=False to see the browser)\n",
    "    scraper = IndeedSeleniumScraper(headless=False)  # Set to True to run in background\n",
    "    \n",
    "    # Scrape jobs\n",
    "    jobs = scraper.scrape_jobs(\n",
    "        job_title=\"\",\n",
    "        location=\"Canada\",\n",
    "        max_pages=2  # Start with 2 pages\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    if jobs:\n",
    "        success = scraper.save_to_csv(\"canada_developer_jobs.csv\")\n",
    "        if success:\n",
    "            print(\"\\nFirst 5 job listings:\")\n",
    "            for i, job in enumerate(jobs[:5], 1):\n",
    "                print(f\"\\n{i}. {job['title']}\")\n",
    "                print(f\"   Company: {job['company']}\")\n",
    "                print(f\"   Location: {job['location']}\")\n",
    "                print(f\"   Salary: {job['salary']}\")\n",
    "    else:\n",
    "        print(\"No jobs were scraped. Please check:\")\n",
    "        print(\"1. Your internet connection\")\n",
    "        print(\"2. If Indeed is blocking requests\")\n",
    "        print(\"3. Try running with headless=False to see what's happening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f8cd63-41d8-4f18-ae7f-e58e68b26cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
