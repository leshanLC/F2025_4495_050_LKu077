{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d98efe9-5fa6-42e4-9cd1-af9d829b7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses table created/verified\n",
      "SQLite database connected: coursera_courses.sqlite\n",
      "\n",
      "Scraping Coursera courses for: 'data science'\n",
      "Scraping page 1...\n",
      "URL: https://www.coursera.org/search?query=data%20science\n",
      "Page source saved to coursera_page_1.html\n",
      "Total unique course cards found: 0\n",
      "Added 0 courses from page 1\n",
      "Scraping page 2...\n",
      "URL: https://www.coursera.org/search?query=data%20science&page=2\n",
      "Error during scraping: Message: invalid session id; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xcdfe43+66515]\n",
      "\tGetHandleVerifier [0x0xcdfe84+66580]\n",
      "\t(No symbol) [0x0xacda6b]\n",
      "\t(No symbol) [0x0xb0b5ab]\n",
      "\t(No symbol) [0x0xb3b086]\n",
      "\t(No symbol) [0x0xb3667c]\n",
      "\t(No symbol) [0x0xb35bf3]\n",
      "\t(No symbol) [0x0xa9e72d]\n",
      "\t(No symbol) [0x0xa9ecae]\n",
      "\t(No symbol) [0x0xa9f14d]\n",
      "\tGetHandleVerifier [0x0xf37353+2521315]\n",
      "\tGetHandleVerifier [0x0xf322d3+2500707]\n",
      "\tGetHandleVerifier [0x0xd07c94+229924]\n",
      "\tGetHandleVerifier [0x0xcf81f8+165768]\n",
      "\tGetHandleVerifier [0x0xcfecad+193085]\n",
      "\t(No symbol) [0x0xa9e3e3]\n",
      "\t(No symbol) [0x0xa9db60]\n",
      "\tGetHandleVerifier [0x0x107c20f+3852191]\n",
      "\tBaseThreadInitThunk [0x0x75bf5d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x76f2d6db+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x76f2d661+561]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lesha\\AppData\\Local\\Temp\\ipykernel_15204\\4058517320.py\", line 97, in scrape_courses\n",
      "    self.driver.get(url)\n",
      "  File \"C:\\Users\\lesha\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 483, in get\n",
      "    self.execute(Command.GET, {\"url\": url})\n",
      "  File \"C:\\Users\\lesha\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 458, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\lesha\\anaconda3\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 232, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.InvalidSessionIdException: Message: invalid session id; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#invalidsessionidexception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x0xcdfe43+66515]\n",
      "\tGetHandleVerifier [0x0xcdfe84+66580]\n",
      "\t(No symbol) [0x0xacda6b]\n",
      "\t(No symbol) [0x0xb0b5ab]\n",
      "\t(No symbol) [0x0xb3b086]\n",
      "\t(No symbol) [0x0xb3667c]\n",
      "\t(No symbol) [0x0xb35bf3]\n",
      "\t(No symbol) [0x0xa9e72d]\n",
      "\t(No symbol) [0x0xa9ecae]\n",
      "\t(No symbol) [0x0xa9f14d]\n",
      "\tGetHandleVerifier [0x0xf37353+2521315]\n",
      "\tGetHandleVerifier [0x0xf322d3+2500707]\n",
      "\tGetHandleVerifier [0x0xd07c94+229924]\n",
      "\tGetHandleVerifier [0x0xcf81f8+165768]\n",
      "\tGetHandleVerifier [0x0xcfecad+193085]\n",
      "\t(No symbol) [0x0xa9e3e3]\n",
      "\t(No symbol) [0x0xa9db60]\n",
      "\tGetHandleVerifier [0x0x107c20f+3852191]\n",
      "\tBaseThreadInitThunk [0x0x75bf5d49+25]\n",
      "\tRtlInitializeExceptionChain [0x0x76f2d6db+107]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x0x76f2d661+561]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed\n",
      "No courses were scraped\n",
      "Check the saved HTML files for debugging\n",
      "\n",
      "Database file: coursera_courses.sqlite\n",
      "CSV backup: coursera_courses_backup.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "class ImprovedCourseraScraper:\n",
    "    def __init__(self, headless=False):  # Set to False for debugging\n",
    "        self.options = Options()\n",
    "        \n",
    "        self.options.add_argument('--no-sandbox')\n",
    "        self.options.add_argument('--disable-dev-shm-usage')\n",
    "        self.options.add_argument('--window-size=1920,1080')\n",
    "        self.options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        self.options.add_argument('--disable-gpu')\n",
    "        self.options.add_argument('--disable-extensions')\n",
    "        \n",
    "        self.options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')\n",
    "        \n",
    "        if headless:\n",
    "            self.options.add_argument('--headless')\n",
    "        \n",
    "        self.driver = webdriver.Chrome(\n",
    "            service=Service(ChromeDriverManager().install()),\n",
    "            options=self.options\n",
    "        )\n",
    "        \n",
    "        self.courses_data = []\n",
    "        self.db_connection = None\n",
    "        \n",
    "    def setup_sqlite_database(self, db_path=\"coursera_courses.sqlite\"):\n",
    "        try:\n",
    "            self.db_connection = sqlite3.connect(db_path)\n",
    "            self._create_courses_table()\n",
    "            print(f\"SQLite database connected: {db_path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error setting up SQLite database: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _create_courses_table(self):\n",
    "        create_table_sql = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS courses (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            title TEXT NOT NULL,\n",
    "            provider TEXT,\n",
    "            instructors TEXT,\n",
    "            rating REAL,\n",
    "            rating_count INTEGER,\n",
    "            duration TEXT,\n",
    "            difficulty_level TEXT,\n",
    "            course_type TEXT,\n",
    "            price TEXT,\n",
    "            description TEXT,\n",
    "            skills_covered TEXT,\n",
    "            link TEXT,\n",
    "            language TEXT,\n",
    "            scraped_date TEXT,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "            UNIQUE(title, provider)\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor = self.db_connection.cursor()\n",
    "        cursor.execute(create_table_sql)\n",
    "        self.db_connection.commit()\n",
    "        cursor.close()\n",
    "        print(\"Courses table created/verified\")\n",
    "\n",
    "    def scrape_courses(self, search_query=\"\", max_pages=2):\n",
    "        try:\n",
    "            for page in range(max_pages):\n",
    "                # Build URL with search query\n",
    "                base_url = \"https://www.coursera.org/search\"\n",
    "                if search_query:\n",
    "                    url = f\"{base_url}?query={search_query.replace(' ', '%20')}\"\n",
    "                    if page > 0:\n",
    "                        url += f\"&page={page + 1}\"\n",
    "                else:\n",
    "                    url = f\"{base_url}\"\n",
    "                    if page > 0:\n",
    "                        url += f\"?page={page + 1}\"\n",
    "                \n",
    "                print(f\"Scraping page {page + 1}...\")\n",
    "                print(f\"URL: {url}\")\n",
    "                \n",
    "                self.driver.get(url)\n",
    "                time.sleep(random.uniform(4, 6))\n",
    "                \n",
    "                # Debug: Save page source for inspection\n",
    "                with open(f\"coursera_page_{page + 1}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(self.driver.page_source)\n",
    "                print(f\"Page source saved to coursera_page_{page + 1}.html\")\n",
    "                \n",
    "                # Wait for page to load\n",
    "                WebDriverWait(self.driver, 15).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "                )\n",
    "                \n",
    "                # Handle popups and consent forms\n",
    "                self._handle_popups()\n",
    "                \n",
    "                # Scroll to load content\n",
    "                self._scroll_page()\n",
    "                \n",
    "                courses_count_before = len(self.courses_data)\n",
    "                self._extract_page_courses_improved()\n",
    "                courses_added = len(self.courses_data) - courses_count_before\n",
    "                \n",
    "                print(f\"Added {courses_added} courses from page {page + 1}\")\n",
    "                \n",
    "                # Save to database after each page\n",
    "                if courses_added > 0 and self.db_connection:\n",
    "                    saved_count = self.save_to_database()\n",
    "                    print(f\"Saved {saved_count} courses to database\")\n",
    "                \n",
    "                if page < max_pages - 1:\n",
    "                    time.sleep(random.uniform(3, 5))\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error during scraping: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        finally:\n",
    "            self.driver.quit()\n",
    "            if self.db_connection:\n",
    "                self.db_connection.close()\n",
    "                print(\"Database connection closed\")\n",
    "        \n",
    "        return self.courses_data\n",
    "\n",
    "    def _handle_popups(self):\n",
    "        \"\"\"Handle various popups that might appear\"\"\"\n",
    "        popup_selectors = [\n",
    "            'button[aria-label=\"Close\"]',\n",
    "            'button[data-e2e=\"close-button\"]',\n",
    "            '.cds-modal-close',\n",
    "            '.rc-ModalCloseButton',\n",
    "            'button[class*=\"close\"]',\n",
    "            '.phoenix-close',\n",
    "            '[data-testid=\"modal-close-button\"]'\n",
    "        ]\n",
    "        \n",
    "        for selector in popup_selectors:\n",
    "            try:\n",
    "                close_btn = WebDriverWait(self.driver, 3).until(\n",
    "                    EC.element_to_be_clickable((By.CSS_SELECTOR, selector))\n",
    "                )\n",
    "                close_btn.click()\n",
    "                print(f\"Closed popup with selector: {selector}\")\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    def _scroll_page(self):\n",
    "        \"\"\"Scroll page to load all content\"\"\"\n",
    "        try:\n",
    "            last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            for _ in range(3):\n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(2)\n",
    "                new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def _extract_page_courses_improved(self):\n",
    "        try:\n",
    "            # More comprehensive course card selectors\n",
    "            course_selectors = [\n",
    "                'li[class*=\"ais-InfiniteHits-item\"]',\n",
    "                '[data-testid*=\"search-result\"]',\n",
    "                '[class*=\"cds-ProductCard\"]',\n",
    "                '.rc-SearchHit',\n",
    "                '[class*=\"course-card\"]',\n",
    "                '.bt3-col-xs-12',  # Bootstrap-based selectors\n",
    "                '.card-info',\n",
    "                'div[data-e2e*=\"course-card\"]'\n",
    "            ]\n",
    "            \n",
    "            all_cards = []\n",
    "            for selector in course_selectors:\n",
    "                try:\n",
    "                    cards = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                    if cards:\n",
    "                        print(f\"Found {len(cards)} elements with selector: {selector}\")\n",
    "                        all_cards.extend(cards)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Remove duplicates by element reference\n",
    "            unique_cards = []\n",
    "            seen_elements = set()\n",
    "            for card in all_cards:\n",
    "                element_id = id(card)\n",
    "                if element_id not in seen_elements:\n",
    "                    seen_elements.add(element_id)\n",
    "                    unique_cards.append(card)\n",
    "            \n",
    "            print(f\"Total unique course cards found: {len(unique_cards)}\")\n",
    "            \n",
    "            for i, card in enumerate(unique_cards):\n",
    "                if i > 0 and i % 2 == 0:\n",
    "                    time.sleep(random.uniform(1, 2))\n",
    "                \n",
    "                course_info = self._extract_course_info_improved(card)\n",
    "                if course_info:\n",
    "                    self.courses_data.append(course_info)\n",
    "                    print(f\"âœ“ Extracted: {course_info['title'][:50]}...\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting courses: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def _extract_course_info_improved(self, card):\n",
    "        try:\n",
    "            # Get the entire card text for debugging\n",
    "            card_text = card.text\n",
    "            if not card_text or len(card_text.strip()) < 10:\n",
    "                return None\n",
    "            \n",
    "            print(f\"Card text preview: {card_text[:100]}...\")\n",
    "            \n",
    "            # Extract title - try multiple selectors\n",
    "            title = None\n",
    "            title_selectors = [\n",
    "                'h2',\n",
    "                'h3',\n",
    "                '[class*=\"title\"]',\n",
    "                '[data-testid*=\"title\"]',\n",
    "                '.card-title',\n",
    "                '.course-name',\n",
    "                'a[href*=\"/learn/\"]',\n",
    "                'a[href*=\"/specializations/\"]'\n",
    "            ]\n",
    "            \n",
    "            for selector in title_selectors:\n",
    "                title = self._safe_extract(card, selector, 'text')\n",
    "                if title and len(title.strip()) > 5:\n",
    "                    title = title.strip()\n",
    "                    break\n",
    "            \n",
    "            if not title:\n",
    "                # Try to extract title from card text\n",
    "                lines = [line.strip() for line in card_text.split('\\n') if line.strip()]\n",
    "                if lines:\n",
    "                    title = lines[0]  # First line is often the title\n",
    "            \n",
    "            if not title:\n",
    "                return None\n",
    "            \n",
    "            # Extract provider\n",
    "            provider = self._extract_provider(card, card_text)\n",
    "            \n",
    "            # Extract rating\n",
    "            rating = self._extract_rating(card, card_text)\n",
    "            \n",
    "            # Extract rating count\n",
    "            rating_count = self._extract_rating_count(card, card_text)\n",
    "            \n",
    "            # Extract other information\n",
    "            duration = self._extract_duration(card_text)\n",
    "            difficulty = self._extract_difficulty(card_text)\n",
    "            course_type = self._extract_course_type(card_text)\n",
    "            price = self._extract_price_info(card_text)\n",
    "            description = self._extract_description(card, card_text)\n",
    "            skills = self._extract_skills(card_text)\n",
    "            \n",
    "            # Extract link\n",
    "            link = self._safe_extract(card, 'a', 'href')\n",
    "            if link and not link.startswith('http'):\n",
    "                link = 'https://www.coursera.org' + link\n",
    "            \n",
    "            return {\n",
    "                'title': title,\n",
    "                'provider': provider or \"Provider not specified\",\n",
    "                'instructors': \"Instructors not specified\",  # Hard to extract from list view\n",
    "                'rating': rating,\n",
    "                'rating_count': rating_count,\n",
    "                'duration': duration or \"Duration not specified\",\n",
    "                'difficulty_level': difficulty or \"Not specified\",\n",
    "                'course_type': course_type or \"Course\",\n",
    "                'price': price or \"Price not specified\",\n",
    "                'description': description or \"Description not available\",\n",
    "                'skills_covered': skills or \"Skills not specified\",\n",
    "                'link': link or \"Link not available\",\n",
    "                'language': \"English\",  # Default assumption\n",
    "                'scraped_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting course info: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _extract_provider(self, card, card_text):\n",
    "        provider_selectors = [\n",
    "            '[data-testid*=\"partner\"]',\n",
    "            '[class*=\"partner-name\"]',\n",
    "            '[class*=\"provider\"]',\n",
    "            '.partner-name',\n",
    "            '.institution'\n",
    "        ]\n",
    "        \n",
    "        for selector in provider_selectors:\n",
    "            provider = self._safe_extract(card, selector, 'text')\n",
    "            if provider:\n",
    "                return provider.strip()\n",
    "        \n",
    "        # Extract from text patterns\n",
    "        patterns = [\n",
    "            r'Offered by\\s+(.+)',\n",
    "            r'from\\s+(.+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, card_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        \n",
    "        return \"Provider not specified\"\n",
    "\n",
    "    def _extract_rating(self, card, card_text):\n",
    "        rating_selectors = [\n",
    "            '[data-testid*=\"rating\"]',\n",
    "            '[class*=\"rating-number\"]',\n",
    "            '.product-ratings',\n",
    "            '.ratings-text'\n",
    "        ]\n",
    "        \n",
    "        for selector in rating_selectors:\n",
    "            rating_text = self._safe_extract(card, selector, 'text')\n",
    "            if rating_text:\n",
    "                match = re.search(r'(\\d+\\.\\d+)', rating_text)\n",
    "                if match:\n",
    "                    return float(match.group(1))\n",
    "        \n",
    "        # Extract from text\n",
    "        match = re.search(r'(\\d+\\.\\d+)\\s*stars?', card_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        \n",
    "        return 0.0\n",
    "\n",
    "    def _extract_rating_count(self, card, card_text):\n",
    "        count_selectors = [\n",
    "            '[data-testid*=\"ratings-count\"]',\n",
    "            '[class*=\"rating-count\"]',\n",
    "            '[class*=\"enrollment-number\"]'\n",
    "        ]\n",
    "        \n",
    "        for selector in count_selectors:\n",
    "            count_text = self._safe_extract(card, selector, 'text')\n",
    "            if count_text:\n",
    "                return self._parse_count(count_text)\n",
    "        \n",
    "        # Extract from text\n",
    "        match = re.search(r'\\(([\\d,]+)\\s*(ratings|reviews)\\)', card_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return self._parse_count(match.group(1))\n",
    "        \n",
    "        return 0\n",
    "\n",
    "    def _parse_count(self, count_text):\n",
    "        try:\n",
    "            count_text = count_text.lower().replace(',', '')\n",
    "            if 'k' in count_text:\n",
    "                return int(float(count_text.replace('k', '')) * 1000)\n",
    "            elif 'm' in count_text:\n",
    "                return int(float(count_text.replace('m', '')) * 1000000)\n",
    "            else:\n",
    "                numbers = re.findall(r'\\d+', count_text)\n",
    "                if numbers:\n",
    "                    return int(numbers[0])\n",
    "        except:\n",
    "            pass\n",
    "        return 0\n",
    "\n",
    "    def _extract_duration(self, card_text):\n",
    "        patterns = [\n",
    "            r'(\\d+\\s*-\\s*\\d+\\s*(months?|weeks?|hours?))',\n",
    "            r'(\\d+\\s*(months?|weeks?|hours?))',\n",
    "            r'Approx\\.\\s*(\\d+\\s*hours?)'\n",
    "        ]\n",
    "        \n",
    "        for pattern in patterns:\n",
    "            match = re.search(pattern, card_text, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def _extract_difficulty(self, card_text):\n",
    "        levels = ['beginner', 'intermediate', 'advanced', 'mixed']\n",
    "        for level in levels:\n",
    "            if level in card_text.lower():\n",
    "                return level.capitalize()\n",
    "        return \"Not specified\"\n",
    "\n",
    "    def _extract_course_type(self, card_text):\n",
    "        types = {\n",
    "            'specialization': 'Specialization',\n",
    "            'professional certificate': 'Professional Certificate',\n",
    "            'guided project': 'Guided Project',\n",
    "            'degree': 'Degree',\n",
    "            'mastertrack': 'MasterTrack'\n",
    "        }\n",
    "        \n",
    "        for key, value in types.items():\n",
    "            if key in card_text.lower():\n",
    "                return value\n",
    "        return \"Course\"\n",
    "\n",
    "    def _extract_price_info(self, card_text):\n",
    "        if 'free' in card_text.lower():\n",
    "            return \"Free\"\n",
    "        elif 'subscription' in card_text.lower():\n",
    "            return \"Subscription\"\n",
    "        elif 'audit' in card_text.lower():\n",
    "            return \"Free Audit\"\n",
    "        else:\n",
    "            # Look for price patterns\n",
    "            match = re.search(r'\\$\\d+\\.?\\d*', card_text)\n",
    "            if match:\n",
    "                return match.group(0)\n",
    "            return \"Price not specified\"\n",
    "\n",
    "    def _extract_description(self, card, card_text):\n",
    "        desc_selectors = [\n",
    "            '[class*=\"description\"]',\n",
    "            '[class*=\"snippet\"]',\n",
    "            '.course-description'\n",
    "        ]\n",
    "        \n",
    "        for selector in desc_selectors:\n",
    "            desc = self._safe_extract(card, selector, 'text')\n",
    "            if desc and len(desc) > 20:\n",
    "                return desc[:500].strip()\n",
    "        \n",
    "        # Use first few meaningful lines from card text\n",
    "        lines = [line.strip() for line in card_text.split('\\n') if line.strip()]\n",
    "        if len(lines) > 1:\n",
    "            # Skip title and provider lines\n",
    "            description_lines = []\n",
    "            for line in lines[2:6]:  # Take lines 2-5 as description\n",
    "                if len(line) > 10 and not any(keyword in line.lower() for keyword in ['rating', 'review', 'enrollment', 'star']):\n",
    "                    description_lines.append(line)\n",
    "            if description_lines:\n",
    "                return ' '.join(description_lines)[:400]\n",
    "        \n",
    "        return \"Description not available\"\n",
    "\n",
    "    def _extract_skills(self, card_text):\n",
    "        # Look for skills mentioned in the text\n",
    "        skills_keywords = ['python', 'sql', 'machine learning', 'data analysis', 'statistics', \n",
    "                          'r programming', 'tableau', 'excel', 'data visualization']\n",
    "        found_skills = []\n",
    "        \n",
    "        for skill in skills_keywords:\n",
    "            if skill in card_text.lower():\n",
    "                found_skills.append(skill)\n",
    "        \n",
    "        if found_skills:\n",
    "            return ', '.join(found_skills)\n",
    "        return \"Skills not specified\"\n",
    "\n",
    "    def _safe_extract(self, parent, selector, attribute='text'):\n",
    "        try:\n",
    "            element = parent.find_element(By.CSS_SELECTOR, selector)\n",
    "            if attribute == 'text':\n",
    "                text = element.text.strip()\n",
    "                return text if text else None\n",
    "            else:\n",
    "                attr = element.get_attribute(attribute)\n",
    "                return attr if attr else None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def save_to_database(self):\n",
    "        if not self.courses_data or not self.db_connection:\n",
    "            print(\"No data to save or database not connected\")\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            cursor = self.db_connection.cursor()\n",
    "            saved_count = 0\n",
    "            \n",
    "            insert_sql = \"\"\"\n",
    "            INSERT OR IGNORE INTO courses (title, provider, instructors, rating, rating_count, duration, \n",
    "                                         difficulty_level, course_type, price, description, skills_covered, \n",
    "                                         link, language, scraped_date)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\"\n",
    "            \n",
    "            for course in self.courses_data:\n",
    "                try:\n",
    "                    cursor.execute(insert_sql, (\n",
    "                        course['title'],\n",
    "                        course['provider'],\n",
    "                        course['instructors'],\n",
    "                        course['rating'],\n",
    "                        course['rating_count'],\n",
    "                        course['duration'],\n",
    "                        course['difficulty_level'],\n",
    "                        course['course_type'],\n",
    "                        course['price'],\n",
    "                        course['description'],\n",
    "                        course['skills_covered'],\n",
    "                        course['link'],\n",
    "                        course['language'],\n",
    "                        course['scraped_date']\n",
    "                    ))\n",
    "                    if cursor.rowcount > 0:\n",
    "                        saved_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error inserting course: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            self.db_connection.commit()\n",
    "            cursor.close()\n",
    "            return saved_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to database: {e}\")\n",
    "            return 0\n",
    "\n",
    "    def debug_page_structure(self):\n",
    "        \"\"\"Debug method to understand page structure\"\"\"\n",
    "        print(\"\\n=== PAGE STRUCTURE DEBUG ===\")\n",
    "        print(f\"Current URL: {self.driver.current_url}\")\n",
    "        print(f\"Page title: {self.driver.title}\")\n",
    "        \n",
    "        # Find all containers that might hold courses\n",
    "        container_selectors = ['main', '#main', '.results', '.search-results', '.ais-InfiniteHits', '.cds-grid']\n",
    "        \n",
    "        for selector in container_selectors:\n",
    "            try:\n",
    "                containers = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                print(f\"Found {len(containers)} containers with selector: {selector}\")\n",
    "                for i, container in enumerate(containers):\n",
    "                    print(f\"Container {i+1} text preview: {container.text[:200]}...\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "def main():\n",
    "    # Initialize scraper with headless=False for debugging\n",
    "    scraper = ImprovedCourseraScraper(headless=False)\n",
    "    \n",
    "    # Setup SQLite database\n",
    "    if not scraper.setup_sqlite_database(\"coursera_courses.sqlite\"):\n",
    "        print(\"Failed to setup database. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    search_query = \"data science\"\n",
    "    pages = 2\n",
    "    \n",
    "    print(f\"\\nScraping Coursera courses for: '{search_query}'\")\n",
    "    \n",
    "    # Scrape and save to database\n",
    "    start_time = time.time()\n",
    "    courses = scraper.scrape_courses(\n",
    "        search_query=search_query,\n",
    "        max_pages=pages\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Display results\n",
    "    if courses:\n",
    "        print(f\"\\nSuccessfully processed {len(courses)} courses in {end_time - start_time:.1f} seconds\")\n",
    "        \n",
    "        # Display sample courses\n",
    "        print(\"\\nSample courses found:\")\n",
    "        for i, course in enumerate(courses[:5]):\n",
    "            print(f\"{i+1}. {course['title']}\")\n",
    "            print(f\"   Provider: {course['provider']}\")\n",
    "            print(f\"   Rating: {course['rating']} ({course['rating_count']} reviews)\")\n",
    "            print(f\"   Type: {course['course_type']}\")\n",
    "            print(f\"   Price: {course['price']}\")\n",
    "            print()\n",
    "        \n",
    "        # Save to CSV\n",
    "        scraper.save_to_csv(\"coursera_courses_backup.csv\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No courses were scraped\")\n",
    "        print(\"Check the saved HTML files for debugging\")\n",
    "    \n",
    "    print(f\"\\nDatabase file: coursera_courses.sqlite\")\n",
    "    print(\"CSV backup: coursera_courses_backup.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c113b-2629-48e1-8894-d734353b469a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
